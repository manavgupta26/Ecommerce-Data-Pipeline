# ğŸ›’ E-Commerce Data Pipeline

A production-grade, end-to-end data engineering project built with **Apache Airflow**, **PostgreSQL**, and **Docker**. This pipeline implements a **medallion architecture** (Bronze â†’ Silver â†’ Gold) to process e-commerce data and generate business intelligence insights.

![Pipeline Architecture](https://img.shields.io/badge/Architecture-Medallion-blue) ![Airflow](https://img.shields.io/badge/Airflow-2.8.1-orange) ![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue) ![Docker](https://img.shields.io/badge/Docker-Compose-blue) ![Python](https://img.shields.io/badge/Python-3.11-green)

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Tech Stack](#tech-stack)
- [Features](#features)
- [Project Structure](#project-structure)
- [Setup Instructions](#setup-instructions)
- [DAG Workflows](#dag-workflows)
- [Data Model](#data-model)
- [Analytics & Visualizations](#analytics--visualizations)
- [Production Features](#production-features)
- [Sample Queries](#sample-queries)
- [Future Enhancements](#future-enhancements)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

This project demonstrates a **real-world data engineering pipeline** that:
- Ingests data from REST APIs and generates realistic e-commerce transactions
- Implements data quality checks and transformations
- Creates business-ready analytics with **RFM segmentation**, **inventory health monitoring**, and **campaign ROI analysis**
- Tracks historical changes using **SCD Type 2** (Slowly Changing Dimensions)
- Provides self-service BI dashboards with **Metabase**

**Use Case**: E-commerce analytics platform for tracking sales, customers, inventory, and marketing campaigns.

---

## ğŸ—ï¸ Architecture

### Medallion Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA SOURCES                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Fake Store   â”‚  â”‚    Order     â”‚  â”‚  Inventory   â”‚   â”‚
â”‚  â”‚     API      â”‚  â”‚  Generator   â”‚  â”‚   Generator  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸ¥‰ BRONZE LAYER (Raw Data)                 â”‚
â”‚  â€¢ bronze_products      â€¢ bronze_orders                 â”‚
â”‚  â€¢ bronze_customers     â€¢ bronze_inventory              â”‚
â”‚  â€¢ bronze_campaigns                                     â”‚
â”‚  âœ“ Full audit trail     âœ“ Source metadata               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“ Data Quality Checks
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ğŸ¥ˆ SILVER LAYER (Cleaned & Validated)         â”‚
â”‚  â€¢ silver_products      â€¢ silver_orders                 â”‚
â”‚  â€¢ silver_customers     â€¢ silver_inventory              â”‚
â”‚  â€¢ silver_campaigns                                     â”‚
â”‚  âœ“ Deduplicated        âœ“ Type validated                 â”‚
â”‚  âœ“ Enriched fields     âœ“ Referential integrity          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“ Aggregations & Analytics
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ğŸ¥‡ GOLD LAYER (Business Analytics)              â”‚
â”‚  â€¢ gold_daily_revenue                                   â”‚
â”‚  â€¢ gold_product_performance                             â”‚
â”‚  â€¢ gold_customer_segments (RFM)                         â”‚
â”‚  â€¢ gold_inventory_health                                â”‚
â”‚  â€¢ gold_campaign_roi                                    â”‚
â”‚  âœ“ Business KPIs       âœ“ Ready for BI tools             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸ“Š VISUALIZATION LAYER                     â”‚
â”‚                    (Metabase)                           â”‚
â”‚  â€¢ Revenue Dashboards   â€¢ Customer Insights             â”‚
â”‚  â€¢ Product Analytics    â€¢ Inventory Alerts              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Infrastructure Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DOCKER COMPOSE STACK                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Airflow   â”‚  â”‚  Airflow   â”‚  â”‚  Warehouse  â”‚     â”‚
â”‚  â”‚ Webserver  â”‚  â”‚ Scheduler  â”‚  â”‚  PostgreSQL â”‚     â”‚
â”‚  â”‚ :8080      â”‚  â”‚            â”‚  â”‚  :5433      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Airflow   â”‚  â”‚  Metadata  â”‚  â”‚  Metabase   â”‚     â”‚
â”‚  â”‚   Worker   â”‚  â”‚ PostgreSQL â”‚  â”‚  :3000      â”‚     â”‚
â”‚  â”‚            â”‚  â”‚  :5432     â”‚  â”‚             â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | Version |
|-----------|-----------|---------|
| **Orchestration** | Apache Airflow | 2.8.1 |
| **Data Warehouse** | PostgreSQL | 15 |
| **Containerization** | Docker Compose | 3.8 |
| **Language** | Python | 3.11 |
| **Visualization** | Metabase | Latest |
| **Object Storage** | MinIO | Latest |
| **API Source** | Fake Store API | - |

### Python Libraries
- `apache-airflow-providers-postgres` - Database connectivity
- `pandas` - Data manipulation
- `faker` - Synthetic data generation
- `requests` - API calls
- `psycopg2-binary` - PostgreSQL adapter

---

## âœ¨ Features

### ğŸ”„ Data Pipeline
- âœ… **Automated daily ingestion** from REST APIs
- âœ… **Incremental loading** with upsert logic
- âœ… **Data quality validation** (email format, price ranges, referential integrity)
- âœ… **Error handling** with retries and alerting
- âœ… **Full audit trail** (source, timestamp, pipeline_run_id)

### ğŸ“Š Analytics
- âœ… **RFM Customer Segmentation** (Recency, Frequency, Monetary)
- âœ… **Product Performance Metrics** (revenue, profit margin, rankings)
- âœ… **Inventory Health Monitoring** (low stock, overstock, dead stock alerts)
- âœ… **Campaign ROI Analysis** (ROAS, cost per order, conversion rates)
- âœ… **Daily Revenue Trends** (YoY growth, weekend patterns)

### ğŸ—‚ï¸ Advanced Features
- âœ… **SCD Type 2** - Historical tracking of price changes and customer tier progression
- âœ… **XCom** - Inter-task communication for data sharing
- âœ… **External Task Sensors** - DAG dependency management
- âœ… **Dynamic Task Generation** - Scalable pipeline design
- âœ… **Metabase Integration** - Self-service BI dashboards

---

## ğŸš€ Setup Instructions

### Prerequisites
- Docker Desktop (4.0+)
- Docker Compose (3.8+)
- 8GB RAM minimum
- 10GB free disk space

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/ecommerce-data-pipeline.git
cd ecommerce-data-pipeline
```

2. **Create required directories**
```bash
mkdir -p dags logs plugins data/incoming data/archive sql scripts tests
```

3. **Build and start services**
```bash
docker-compose build
docker-compose up -d
```

4. **Wait for services to initialize** (2-3 minutes)
```bash
# Check service health
docker-compose ps
```

5. **Access Airflow UI**
- URL: http://localhost:8080
- Username: `airflow`
- Password: `airflow`

6. **Configure Airflow connection**
```bash
# Add warehouse database connection
docker exec -it  airflow connections add 'warehouse_db' \
    --conn-type 'postgres' \
    --conn-host 'warehouse-db' \
    --conn-schema 'data_warehouse' \
    --conn-login 'warehouse' \
    --conn-password 'warehouse' \
    --conn-port 5432
```

Or via Airflow UI:
- Go to Admin â†’ Connections â†’ Add
- Connection Id: `warehouse_db`
- Connection Type: `Postgres`
- Host: `warehouse-db`
- Schema: `data_warehouse`
- Login: `warehouse`
- Password: `warehouse`
- Port: `5432`

7. **Trigger the pipeline**
```bash
# In Airflow UI, unpause and trigger:
# 1. bronze_ingestion
# 2. silver_transformation (auto-triggers)
# 3. gold_analytics (auto-triggers)
# 4. scd_maintenance
```

8. **Access Metabase** (optional)
- URL: http://localhost:3000
- Setup account and connect to `warehouse-db:5432/data_warehouse`

---
